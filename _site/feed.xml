<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sirisha Rambhatla</title>
    <description>Hello World!  
</description>
    <link>https://srambhatla.github.io//</link>
    <atom:link href="https://srambhatla.github.io//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 24 Jul 2017 14:01:03 -0500</pubDate>
    <lastBuildDate>Mon, 24 Jul 2017 14:01:03 -0500</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Generalized Robust PCA</title>
        <description>&lt;p&gt;We consider the generalized robust PCA problem, for more details please refer to the [&lt;a href=&quot;/docs/Dictionary_based_generalization_of_robust_PCA_Sirisha_R.pdf&quot;&gt;slides&lt;/a&gt;].&lt;/p&gt;

&lt;div&gt;&lt;img src=&quot;/docs/grpca/main_fig.png&quot; style=&quot;width:550px;display:block; margin: 0px auto;margin-top: -5px;margin-bottom: 5px;&quot; /&gt;&lt;/div&gt;

&lt;h1 id=&quot;demo-target-detection-in-hyperspectral-imaging&quot;&gt;Demo: Target detection in Hyperspectral imaging&lt;/h1&gt;

&lt;p&gt;We have here a demo showing the performance of the proposed algorithm on the &lt;a href=&quot;http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes&quot;&gt;Indian Pines&lt;/a&gt; dataset. The video shows the recovery of class 16, the stone-steel towers, for increasing values of the regularization parameter, which penalizes the sparsity of the coefficient matrix.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: center&quot;&gt;
&lt;video style=&quot;display:block; margin: 0px auto;margin-top: -5px;margin-bottom: 5px;&quot; width=&quot;620&quot; controls=&quot;&quot; preload=&quot;&quot;&gt; 
    &lt;source src=&quot;/docs/grpca/LplusDA_hyper_spectral.mp4&quot; /&gt; 
    &lt;source src=&quot;/docs/grpca/LplusDA_hyper_spectral.webm&quot; /&gt; 
&lt;/video&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Interestingly, at about 5 sec. into the video, a diagonal line appears at the top right corner. This line corresponds to the rail-tracks in the scene, that is mostly composed of agricultural land, and are closely related to the spectral signatures of the stone-steel towers.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;script src=&quot;//platform.linkedin.com/in.js&quot; type=&quot;text/javascript&quot;&gt; lang: en_US&lt;/script&gt;
&lt;script type=&quot;IN/Share&quot;&gt;&lt;/script&gt;    &lt;a href=&quot;https://twitter.com/share&quot; class=&quot;twitter-share-button&quot; data-text=&quot;An interesting read &quot; data-via=&quot;siri_r&quot; data-count=&quot;none&quot;&gt;Tweet&lt;/a&gt; &lt;script&gt;!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?&#39;http&#39;:&#39;https&#39;;if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+&#39;://platform.twitter.com/widgets.js&#39;;fjs.parentNode.insertBefore(js,fjs);}}(document, &#39;script&#39;, &#39;twitter-wjs&#39;);&lt;/script&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 11 May 2017 16:36:43 -0500</pubDate>
        <link>https://srambhatla.github.io//grpca/2017/05/11/HyperSpectral.html</link>
        <guid isPermaLink="true">https://srambhatla.github.io//grpca/2017/05/11/HyperSpectral.html</guid>
        
        
        <category>grpca</category>
        
      </item>
    
      <item>
        <title>Semi-Blind Morphological Component Analysis</title>
        <description>&lt;p&gt;This tutorial is an overview of my thesis work carried out at the Department of Electrical and Computer Engineering, University of Minnesota-Twin Cities. My thesis work examines a semi-blind source separation problem which finds applications in audio, image, and video processing. The primary aim of this tutorial is to develop an overall intuitive understanding of my work. Suitable examples from our day-to-day lives are employed to motivate and develop the algorithmic framework.&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;If you have ever been to a really noisy party or a large gathering, you must have noticed that you can turn your attention to a specific person and &lt;i&gt;listen&lt;/i&gt; to him/her in spite of all the other sounds. It is interesting how you can recognize and keep track of which voice(s) to follow. This process of selective hearing, in signal processing literature, is referred to as the &lt;i&gt;cocktail-party&lt;/i&gt; problem or the source separation problem. This problem has been well studied in literature and is of great interest in the signal processing community. However, most of the previous work in this area deals with separating the sources based on either of two simplifying assumptions [&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0893608000000265&quot;&gt;ICA&lt;/a&gt;],&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The sources (speakers) which are inherently &lt;i&gt;independent&lt;/i&gt;, meaning they sound very differently to begin with.&lt;/li&gt;
  &lt;li&gt;The methods assume that multiple mixtures, equal to the number of individual sources, are available.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In real life situations such &lt;i&gt;independence&lt;/i&gt; and availability of these multiple mixtures of the sources are luxuries that we seldom have. For the source separation task we set out to solve at the cocktail-party, the voices of the speakers are somewhat similar, and we say that the sources (voices of individual speakers) are correlated. In addition, because we perform this task (separation of one speakerâ€™s sound from many) on a single recording, this is a &lt;i&gt;single channel&lt;/i&gt; source separation task. In this regard, one can view the source separation task as disentangling a mixture of often correlated sources. In cases where none of the sources are known &lt;i&gt;a priori&lt;/i&gt;, the problem is known as a Blind Source Separation Problem and when knowledge about some of the sources is available, we refer to it as a Semi-Blind Source Separation Problem.&lt;/p&gt;

&lt;h1 id=&quot;a-motivating-example-in-audio-forensics&quot;&gt;A Motivating Example in Audio Forensics&lt;/h1&gt;

&lt;p&gt;The semi-blind source separation problem studied in this work is motivated from its application in electroshock law enforcement devices. These devices, when fired, eject probes which attach to the suspect and deliver electric current to restrict their movement. A microphone mounted on the gun records the sounds during the event, which is a mixture of ambient noise (people talking/shouting) along with a signal which indicates the status of the device (whether it was delivering current or not). It is often of interest to determine whether the probes were successfully attached and delivering current. However, due to the ambient noise, the fact the two states of the device (delivering and not-delivering current) are highly correlated and other non-idealities, we have a somewhat difficult task at hand.&lt;/p&gt;

&lt;h1 id=&quot;a-visit-to-the-minnesota-orchestra&quot;&gt;A visit to the Minnesota Orchestra&lt;/h1&gt;

&lt;p&gt;After the hostile situation we encountered above, it is time we relax a little by visiting the Minnesota Orchestra. Suppose that you are at the Minnesota Orchestra and after the first act your friends are excitedly discussing about the Cello in the piece you just heard. Now, imagine you have no idea about how the Cello sounds like. What would you do?&lt;/p&gt;

&lt;p&gt;You have the following options:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Case 1&lt;/strong&gt;: Listen to a sample of a Cello before the next act.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Case 2:&lt;/strong&gt; Assuming that you can identify all other instruments, try identifying the Cello and learn what it sounds like during the next act.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These two processes by which you recognize the instrument (Cello) are at the heart of Machine Learning literature. In the cases described above, you either have the training data (Case 1) to learn the instruments or you have the knowledge about all other instruments and you learn the features specific to Cello, on the fly, from the data (Case 2, referred to as an &lt;i&gt;online &lt;/i&gt;methodology).&lt;/p&gt;

&lt;p&gt;In the situation described above, we often employ the terms like &lt;i&gt;training&lt;/i&gt; and &lt;i&gt;learning&lt;/i&gt;. Before we delve into the algorithmic specifics of the original problem of semi-blind source separation we set out to solve, let us get introduced to these terms and a new technique available in data analysis and machine learning viz Dictionary Learning.&lt;/p&gt;

&lt;h2 id=&quot;dictionary-learning&quot;&gt;Dictionary Learning&lt;/h2&gt;
&lt;p&gt;The word dictionary paints a picture of a resource which contains the meanings of all the words of a language. In an analogous fashion, one can create a dictionary of types of cats, dogs etc., which gives us information about types of cats or dogs respectively. It is assumed that a dictionary of dogs must not be used to look up cats and &lt;i&gt;vice versa&lt;/i&gt;. However, it is important to note that both cats and dogs have some features like four feet, two-eyes etc. which are common. In this regard, we note that a good dictionary for a specific class has the distinguishing features of that class i.e. the features that can be used to identify the class.&lt;/p&gt;

&lt;p&gt;There is yet another term to be tackled before we describe Dictionary Learning, this is &lt;i&gt;Sparsity&lt;/i&gt;. When we say that a signal has a &lt;i&gt;Sparse&lt;/i&gt; representation in a dictionary, we mean that that signal can be formed by using a few elements of a specific Dictionary.  It is like saying that you have a set of spices and you use a certain (small) number of spices for a specific dish. These individual spices will form the &lt;i&gt;sparse&lt;/i&gt; basis for all spice preparations you will use in you meals. All these individual spices hence form the dictionary of spices.&lt;/p&gt;

&lt;p&gt;Now, Dictionary Learning is a process by which we aim to learn these distinguishing features of a class from a dataset (known as &lt;i&gt;training data&lt;/i&gt;). This technique essentially learns the &lt;i&gt;sparsifying&lt;/i&gt; features of a dataset. So why are we interested in sparsifying dictionaries (dictionaries which yield sparse representations)? Sparsifying dictionaries help us to represent the signals succinctly, such compact representations can help us define a particular class efficiently. When such dictionaries are learned on the go, without the use of prior training, it is known as &lt;i&gt;Online Dictionary Learning&lt;/i&gt; [&lt;a href=&quot;http://www.jmlr.org/papers/v11/mairal10a.html&quot;&gt;Mairal 2010&lt;/a&gt;].&lt;/p&gt;

&lt;h1 id=&quot;semi-blind-morphological-component-analysis&quot;&gt;Semi-Blind Morphological Component Analysis&lt;/h1&gt;
&lt;div&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/Model_sims.png&quot; style=&quot;width:550px;display:block; margin: 0px auto;margin-top: -5px;margin-bottom: 5px;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;revisiting-the-cellist-the-sbmca-algorithmic-framework&quot;&gt;Revisiting the Cellist: the SBMCA Algorithmic framework&lt;/h2&gt;

&lt;p&gt;We describe the algorithmic motivation to solve the single channel semi-blind source separation problem based on the &lt;i&gt;Online&lt;/i&gt; Dictionary Learning technique discussed above by using the technique similar to Case 2 described in Section 3.&lt;/p&gt;

&lt;p&gt;Imagine that you have individual dictionaries containing the defining features of each instrument being played at the orchestra except for the Cello. Our essential aim here is to find the part of the musical piece which cannot be represented in these &lt;i&gt;a priori&lt;/i&gt; known dictionaries and learn a new dictionary of features describing this unrepresented part (or instrument). This new dictionary (for our example) hence describes the Cello.&lt;/p&gt;

&lt;p&gt;This forms the algorithmic basis of the technique developed to solve the single channel semi-blind source separation problem. More formally, in each iteration of the algorithm we aim to find the representation of a signal in a set of known dictionaries and in the next step learn the unknown dictionary. After a few iterations, we have the desired source separation via their representations in these distinct dictionaries. We call this algorithmic framework as the Semi-Blind Morphological Component Analysis (SBMCA) as it is similar to the Morphological Component Analysis (MCA) [&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/1510691/&quot;&gt;Starck 2005&lt;/a&gt;], [&lt;a href=&quot;https://arxiv.org/abs/1004.3006&quot;&gt;Donoho 2010&lt;/a&gt;], [&lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/4337756/&quot;&gt;Bobin 2007&lt;/a&gt;] technique for which all dictionaries are known.&lt;/p&gt;

&lt;h2 id=&quot;back-to-the-audio-forensics-application&quot;&gt;Back to the Audio Forensics Application&lt;/h2&gt;
&lt;p&gt;For the Audio Forensics application described in Section 2, we can obtain the information about the delivering and non-delivering current states by triggering the device in a laboratory setting. We form the known dictionaries by using this information about the state signals of the device. In addition, we use the algorithm described above to separate the state signal from the unknown background signal. Subsequently, the state signal can be used to identify the time instants at which the current was being delivered by the electro-shock law enforcement device.&lt;/p&gt;

&lt;h1 id=&quot;results&quot;&gt;Results&lt;/h1&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/methods_and_dicts.png&quot; style=&quot;width:550px;display:block; margin: 0px auto;margin-top: -5px;margin-bottom: 5px;&quot; /&gt;&lt;/div&gt;

&lt;table cellpadding=&quot;4&quot; cellspacing=&quot;10&quot; align=&quot;left&quot;&gt;
  &lt;tr&gt;
  &lt;td colspan=&quot;3&quot;&gt; &lt;div text-align=&quot;center&quot; style=&quot;margin-top:-80px;&quot;&gt; &lt;strong&gt;Original Mixture&lt;/strong&gt;&lt;/div&gt;&lt;br /&gt;
  &lt;img text-align=&quot;center&quot; style=&quot;width:500px;display:block;margin-left: auto;margin-right: auto;margin-top:-10px;&quot; src=&quot;/docs/sbmca_asilomar_data/OrigMix.png&quot; /&gt; &lt;br /&gt;
  &lt;audio align=&quot;center&quot; style=&quot;width:500px;display:block;margin-left: auto;margin-right: auto;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/OrigMix.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt; &lt;/td&gt;
  &lt;/tr&gt;
&lt;!--SBMCA--&gt;
  &lt;tr&gt;
    &lt;td rowspan=&quot;2&quot;&gt; &lt;div style=&quot;-moz-transform: rotate(-90.0deg);-o-transform: rotate(-90.0deg);-webkit-transform: rotate(-90.0deg);filter: progid: DXImageTransform.Microsoft.BasicImage(rotation=0.083);transform: rotate(-90.0deg);float:left;&quot;&gt;SBMCA&lt;/div&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XpSBMCA.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:left;&quot; /&gt; &lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XuSBMCA.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:right;&quot; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:left;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XpSBMCA.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt; &lt;/td&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:right;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XuSBMCA.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;!--DCT--&gt;
  &lt;tr&gt;
    &lt;td rowspan=&quot;2&quot;&gt; &lt;div style=&quot;-moz-transform: rotate(-90.0deg);-o-transform: rotate(-90.0deg);-webkit-transform: rotate(-90.0deg);filter: progid: DXImageTransform.Microsoft.BasicImage(rotation=0.083);transform: rotate(-90.0deg);float:left;&quot;&gt;MCA DCT&lt;/div&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XpDCT.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:left;&quot; /&gt; &lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XuDCT.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:right;&quot; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;br /&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:left;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XpDCT.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt; &lt;/td&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:right;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XuDCT.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;!--EYE--&gt;
  &lt;tr&gt;
    &lt;td rowspan=&quot;2&quot;&gt; &lt;div style=&quot;-moz-transform: rotate(-90.0deg);-o-transform: rotate(-90.0deg);-webkit-transform: rotate(-90.0deg);filter: progid: DXImageTransform.Microsoft.BasicImage(rotation=0.083);transform: rotate(-90.0deg);float:left;&quot;&gt;MCA Identity&lt;/div&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XpEYE.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:left;&quot; /&gt; &lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XuEYE.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:right;&quot; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;br /&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:left;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XpEYE.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt; &lt;/td&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:right;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XuEYE.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;!--NNSC--&gt;
  &lt;tr&gt;
    &lt;td rowspan=&quot;2&quot;&gt; &lt;div style=&quot;-moz-transform: rotate(-90.0deg);-o-transform: rotate(-90.0deg);-webkit-transform: rotate(-90.0deg);filter: progid: DXImageTransform.Microsoft.BasicImage(rotation=0.083);transform: rotate(-90.0deg);float:left;&quot;&gt;NNSC&lt;/div&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XpNNSC.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:left;&quot; /&gt; &lt;/td&gt;
    &lt;td&gt;&lt;img src=&quot;/docs/sbmca_asilomar_data/XuNNSC.png&quot; alt=&quot;Drawing&quot; style=&quot;width:350px;float:right;&quot; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;br /&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:left;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XpNNSC.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt; &lt;/td&gt;
    &lt;td&gt;&lt;audio style=&quot;width:350px;display:block;float:right;margin-top: -10px;&quot; controls=&quot;&quot; preload=&quot;&quot;&gt;&lt;source type=&quot;audio/wav&quot; src=&quot;/docs/sbmca_asilomar_data/XuNNSC.wav&quot; /&gt;&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;&lt;/audio&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;br /&gt;
   &lt;br /&gt;
&lt;/table&gt;

&lt;h1 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;We motivate and propose a technique to solve the single channel semi-blind source separation problem via Semi-Blind Morphological Component Analysis. We base our discussion on intuition and motivating examples from day to day life. For a deeper analysis, algorithmic details and the results please see [&lt;a href=&quot;http://ieeexplore.ieee.org/document/6810587/&quot;&gt;Rambhatla 2013&lt;/a&gt;].&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;script src=&quot;//platform.linkedin.com/in.js&quot; type=&quot;text/javascript&quot;&gt; lang: en_US&lt;/script&gt;
&lt;script type=&quot;IN/Share&quot;&gt;&lt;/script&gt;    &lt;a href=&quot;https://twitter.com/share&quot; class=&quot;twitter-share-button&quot; data-text=&quot;An interesting read &quot; data-via=&quot;siri_r&quot; data-count=&quot;none&quot;&gt;Tweet&lt;/a&gt; &lt;script&gt;!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?&#39;http&#39;:&#39;https&#39;;if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+&#39;://platform.twitter.com/widgets.js&#39;;fjs.parentNode.insertBefore(js,fjs);}}(document, &#39;script&#39;, &#39;twitter-wjs&#39;);&lt;/script&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 15 Nov 2016 15:36:43 -0600</pubDate>
        <link>https://srambhatla.github.io//sbmca/2016/11/15/SBMCA.html</link>
        <guid isPermaLink="true">https://srambhatla.github.io//sbmca/2016/11/15/SBMCA.html</guid>
        
        
        <category>sbmca</category>
        
      </item>
    
  </channel>
</rss>
